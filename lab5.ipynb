{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ferit-osirv/lab5/blob/main/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.png\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Image Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This command must be run before starting to do each lab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf clone && git clone https://github.com/ferit-osirv/lab5 clone && cp -a clone/. ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![](images/conv.png)\n",
    "\n",
    "Generally, convolution is a mathematical operation between two functions. In the context of this assignment, however, we will focus on discrete 2D convolution between two square images, as that is most relevant for image processing. Convolution is denoted as $I(A) \\star k(B)$ where $I(A)$ is an image $I(A) \\in \\mathbb{R}^{W \\times H}$ and $k(B)$ is a matrix $k(B) \\in \\mathbb{R}^{a \\times b}$ indexed by locations $B \\in \\mathbb{N}^2$ called the **convolutional kernel**. At pixel $(x, y)$, the convolution operation is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "(I \\star k)(x, y) = \\sum_{i=-a}^{a} \\sum_{j=-b}^{b} I[x + i, y + j] k[i, j]\n",
    "\\end{equation}\n",
    " \n",
    "Explained differently, the resulting image is produced by sliding the kernel over the input image pixel by pixel. At each pixel location, values where the kernel and the image overlap are multiplied, and all of the products are summed together to form the corresponding pixel's value in the output image.\n",
    "\n",
    "![](images/no_padding_no_strides.gif)\n",
    "\n",
    "While mathematically a simple operation, convolution is exceedingly powerful and can produce almost endless transformations of an image. It's most commonly used for filtering --- a convolution can elegantly find patterns in the image and increase their intensity. One such example is the convolution with a kernel called the Prewitt operator:\n",
    "\n",
    "\\begin{equation}\n",
    "I_y(A) = I(A) \\star \\begin{bmatrix}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "When convolved with this kernel, the resulting image has high-intensity pixels in regions where vertical edges are present, and low intensity everywhere else. This can be seen in the following image:\n",
    "\n",
    "![](images/prewitt-example.png)\n",
    "\n",
    "Vertical edges necessarily have to have a large jump in values going from left to right or right to left. Otherwise, there would be no perceptible edge. This kernel takes advantage of that fact to accentuate parts of the image where there is such a jump. It does this by replacing each pixel with the difference between the pixels on its left and its right.\n",
    "\n",
    "This process happens as follows. For each pixel of the input image, the kernel is placed such that it is centered on that pixel. This means that the values of the pixel as well as its neighbors above and below are all multiplied by zero. The neighbors on the left are multiplied by -1, and the ones on the right are multiplied by 1. Summed together, the result represents the sum of the values on the right of the pixel, minus the sum of the values on the left.\n",
    "\n",
    "To illustrate this, let us consider $1 \\times 3$ region of the image where no vertical edges are present:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "128 & 130 & 136\\\\\n",
    "\\end{bmatrix}\n",
    "\\star\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\sum_{i,j}\n",
    "\\begin{bmatrix}\n",
    "-1 \\times 0 + 0 \\times 128 + 1 \\times 130\\\\ \n",
    "-1 \\times 128 + 0 \\times 130 + 1 \\times 136\\\\\n",
    "-1 \\times 130 + 0 \\times 136 + 1 \\times 0\\\\\n",
    "\\end{bmatrix}\n",
    "= 8\n",
    "\\end{equation}\n",
    "\n",
    "This section of the image does not contain a vertical edge, so the convolution result is a relatively low value. In a standard image with values in $[0, 255)$, 8 would appear almost completely black.\n",
    "\n",
    "However, consider some section of the image where a vertical edge is indeed present:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "63 & 66 & 132\\\\\n",
    "\\end{bmatrix}\n",
    "\\star\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\sum_{i,j}\n",
    "\\begin{bmatrix}\n",
    "-1 \\times 0 + 0 \\times 64 + 1 \\times 66\\\\ \n",
    "-1 \\times 64 + 0 \\times 66 + 1 \\times 132\\\\\n",
    "-1 \\times 66 + 0 \\times 132 + 1 \\times 0\\\\\n",
    "\\end{bmatrix}\n",
    "= 68\n",
    "\\end{equation}\n",
    "\n",
    "The value is now much larger due to the difference between the left and right sides of the image. This example demonstrates how a relatively simple kernel can capture complex features of an image.\n",
    "\n",
    "Beyond edge detection, there are many commonly used convolution kernels to perform tasks such as blurring, sharpening, or denoising images. A convolutional neural network can leverage the power of the convolution by stringing together sequences of intricate kernels to match complex patterns in the image.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "- https://vincmazet.github.io/bip/filtering/convolution.html\n",
    "- https://arxiv.org/pdf/1603.07285.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Assignment 1: Implementing Convolution\n",
    "> \n",
    "> We will first implement a convolution operation from scratch. Convert the following equation into code:\n",
    "> \n",
    "> \\begin{equation}\n",
    "> (I \\star k)(x, y) = \\sum_{i=1}^{a} \\sum_{j=1}^{b} I[x + i, y + j] k[i, j].\n",
    "> \\end{equation}\n",
    "> \n",
    "> This equation defines the convolution value for a single pixel $(x, y)$, where $I$ is the image and $k$ is a kernel of size $a \\times b$. You will need to perform this operation for each pixel. Complete `convolve_py` by returning a convolved image.\n",
    "> \n",
    "> **Finish the code blocks below at the TODO comments. You do not need to change the rest of the code, or code blocks that do not have TODO comments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_py(img, kernel):\n",
    "  '''\n",
    "  Convolves an image with a kernel.\n",
    "  Uses pure Python (no Numpy).\n",
    "\n",
    "  Args:\n",
    "    img: 2D numpy array of the image (grayscale, e.g. (128,128))\n",
    "    kernel: 2D numpy array of the kernel\n",
    "  '''\n",
    "  # Get the dimensions of the image and kernel\n",
    "  img_height, img_width = img.shape\n",
    "  kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "  conv_result = np.zeros(img.shape)\n",
    "  img = np.pad(img, (1, 1), 'constant', constant_values=(0, 0))\n",
    "\n",
    "  for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "      # TODO: compute pixel (x, y) using equation above\n",
    "      # Note: If the kernel goes outside the boundary of the image, assume that the values outside the image are zero.\n",
    "      # Note: In mathematical notation, matrix indices start at 1. In Python, matrix indices start at 0.\n",
    "      # Note: The `img` pixel (x, y) is `img[y, x]`.\n",
    "\n",
    "  return conv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('images/cells.jpg', cv.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "kernel = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "\n",
    "img_out = convolve_py(img, kernel)\n",
    "print(img_out.min(), img_out.max())\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Assignment 2: Speeding up convolution with numpy\n",
    "> \n",
    "> This time, implement the equation above using Numpy functions on matrices to calculate the convolved pixel value as `np.sum(window * kernel)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_np(img, kernel):\n",
    "  '''\n",
    "  Convolves an image with a kernel.\n",
    "  Uses Numpy.\n",
    "\n",
    "  Args:\n",
    "    img: 2D numpy array of the image (grayscale)\n",
    "    kernel: 2D numpy array of the kernel\n",
    "  '''\n",
    "  # Get the dimensions of the image and kernel\n",
    "  img_height, img_width = img.shape\n",
    "  kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "  conv_result = np.zeros(img.shape)\n",
    "  img = np.pad(img, ((1, 1), (1, 1)), 'constant', constant_values=0)\n",
    "\n",
    "  for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "      # TODO\n",
    "\n",
    "  return conv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/cells.jpg', cv.IMREAD_GRAYSCALE)\n",
    "img_out = convolve_np(img, kernel)\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check which implementation is faster using the timeit library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Time the pure Python version\n",
    "time_py = timeit.timeit('convolve_py(img, kernel)', number=5, globals=globals())\n",
    "print('Pure Python: {:.5f}s'.format(time_py))\n",
    "\n",
    "# Time the dot product version (should be a few seconds faster)\n",
    "time_np = timeit.timeit('convolve_np(img, kernel)', number=5, globals=globals())\n",
    "print('NumPy: {:.5f}s'.format(time_dot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding kernels\n",
    "\n",
    "Different convolutional kernels can achieve different effects such as:\n",
    "\n",
    " - edge detection\n",
    " - image engancement (e.g. sharpening)\n",
    " - blurring\n",
    " - denoising\n",
    " - feature detection\n",
    "\n",
    "You can see various examples of kernels here:\n",
    "\n",
    " - https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    " - https://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Assignment 3: Edge Detection\n",
    "> \n",
    "> Find a good convolutional kernel to perform edge detection on the cell image.\n",
    "> \n",
    "> Use the cv.filter2D function with your chosen kernel and display the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Assignment 4: Edge Detection with Blur\n",
    ">\n",
    "> Find a convolutional kernel to blur the image and display the blurred result.\n",
    ">\n",
    "> Then, apply the edge detection kernel (from Assignment 3) on the blurred image and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Assignment 4: Using Large Kernels\n",
    "> \n",
    "> The next code block constructs an image. You job is to recreate the image using a convolution.\n",
    "> \n",
    "> Hint: https://vincmazet.github.io/bip/filtering/convolution.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = np.zeros((100, 100))\n",
    "circle_origins = [(50, 50), (20, 20), (80, 20)]\n",
    "circle_radius = 10\n",
    "\n",
    "for (x, y) in circle_origins:\n",
    "  img_out = cv.circle(img_out, (x, y), circle_radius, 1, -1)\n",
    "\n",
    "plt.imshow(img_out, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.zeros((circle_radius * 2 + 1, circle_radius * 2 + 1))\n",
    "kernel = cv.circle(kernel, (circle_radius, circle_radius), circle_radius, 1, -1)\n",
    "plt.imshow(kernel, cmap='gray')\n",
    "\n",
    "img = np.zeros((100, 100))\n",
    "\n",
    "# TODO: Modify `img` such that a convolution img * kernel produces the same result as `img_out`.\n",
    "\n",
    "\n",
    "# OpenCV's built-in convolution function:\n",
    "img = cv.filter2D(img, -1, kernel)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Convolutions for Feature Detection\n",
    "\n",
    "Assume we want to detect the eyes on the following image:\n",
    "\n",
    "![](images/woman_darkhair.png)\n",
    "\n",
    "Notice that the eyes consist of a light region and then a dark region (iris). We may be able to detect the eyes using the following kernel:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & -1 & -1\\\\\n",
    "1 & 1 & -1 & -1\\\\\n",
    "1 & 1 & -1 & -1\\\\\n",
    "1 & 1 & -1 & -1\\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "This kernel will take the difference between the left two pixels and the right two pixels. If the pixels on the left are high and on the right are low, the resulting value will be high.\n",
    "\n",
    "> ### Assignment 5: Eye Detection\n",
    ">\n",
    "> Implement a convolution with the above kernel in the next code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/woman_darkhair.png', cv.IMREAD_GRAYSCALE)\n",
    "img = cv.resize(img, (0, 0), fx=0.5, fy=0.5)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "kernel = # TODO: Write the kernel from above as a numpy matrix\n",
    "\n",
    "img_out = cv.filter2D(img, -1, kernel)\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Assignment 6: Mouth Detection\n",
    ">\n",
    "> Let's also find the mouth. Guided by the patterns you see in the pixel intensities, try to construct a kernel which will highlight the mouth in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/woman_darkhair.tif', cv.IMREAD_GRAYSCALE)\n",
    "cv.imwrite('images/woman_darkhair.png', img)\n",
    "\n",
    "kernel = # TODO: Write a kernel to find the mouth\n",
    "\n",
    "img_out = cv.filter2D(img, -1, kernel)\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Theorem\n",
    "\n",
    "The **convolution theorem** states:\n",
    "\n",
    "> *Convolution in the spatial domain corresponds to element-wise multiplication in the frequency domain.*\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "\\begin{equation}\n",
    "f * g = \\mathcal{F}^{-1} \\left( \\mathcal{F}(f) \\cdot \\mathcal{F}(g) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Where:\n",
    "- $ f $ is the input image (spatial domain),\n",
    "- $ g $ is the kernel (spatial domain),\n",
    "- $ \\mathcal{F} $ denotes the Fourier Transform,\n",
    "- $ * $ denotes convolution.\n",
    "\n",
    "> ### Assignment 7: Convolution Theorem\n",
    "> \n",
    "> 1. **Load an Image and Kernel**:\n",
    ">    - Use a grayscale image and a small convolution kernel (e.g., Gaussian blur or edge detection kernel).\n",
    "> \n",
    "> 2. **Perform Convolution in Two Ways**:\n",
    ">    - **Spatial Domain**: Convolve the image with the kernel using the `convolve_py` function you implemented earlier.\n",
    ">    - **Frequency Domain**:\n",
    ">      - Compute the Fourier Transform of both the image and the kernel.\n",
    ">      - Multiply the transforms element-wise.\n",
    ">      - Perform the **inverse Fourier Transform** to return to the spatial domain.\n",
    "> \n",
    "> 3. **Compare Results**:\n",
    ">    - Visualize the results of both approaches.\n",
    ">    - Analyze and explain why the outputs are the same.\n",
    "> \n",
    "> **Hints**:\n",
    ">\n",
    "> You will need to **pad the kernel** to match the size of the image before applying the Fourier Transform. This means you will create a new matrix the same size as the image, where:\n",
    ">\n",
    "> The original kernel is placed in the top-left corner of the matrix. The rest of the matrix is filled with zeros.\n",
    ">\n",
    "> Since the kernel needs to be centered during convolution, you must roll (shift) the padded kernel so that its center aligns with the center of the image. This ensures proper alignment in the frequency domain.\n",
    "> \n",
    "> Use `numpy.fft.fft2` for the Fourier Transform and `numpy.fft.ifft2` for the inverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Don't forget to save the notebook on GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
